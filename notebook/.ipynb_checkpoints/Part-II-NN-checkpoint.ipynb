{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.system(\"taskset -p 0xff %d\" % os.getpid())\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 1\n",
    "session = tf.Session(config=config)\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def _read_csv(data_dir, file_name):\n",
    "    import csv\n",
    "    with open(data_dir + '/' + file_name + '.csv', 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=',')\n",
    "        return list(reader)\n",
    "\n",
    "def _read_text(data_dir, file_name):\n",
    "    with open(data_dir + '/' + file_name + '.txt', 'r') as textfile:\n",
    "        return textfile.readlines()\n",
    "    \n",
    "def _translate(text, alphabet):\n",
    "    dictionary = dict(zip(alphabet, range(len(alphabet))))\n",
    "    return np.array([dictionary[t] for t in text if t != '\\n'])\n",
    "    \n",
    "alphabet = _read_csv('../data/part1-data', 'alphabet')[0]\n",
    "P = np.array(_read_csv('../data/part1-data', 'letter_probabilities')[0], dtype=np.float64)\n",
    "M = np.array(_read_csv('../data/part1-data', 'letter_transition_matrix'), dtype=np.float64)\n",
    "cipher_function = _read_csv('../data/part1-data', 'cipher_function')[0]\n",
    "plaintext = _read_text('../data/part1-data', 'plaintext')[0]\n",
    "ciphertext = _read_text('../data/part1-data', 'ciphertext')[0]\n",
    "traintext = _read_text('../data/part2-data', 'plaintext_warandpeace')[0]\n",
    "\n",
    "logP = np.log(P)\n",
    "M[M==0] = 1\n",
    "logM = np.log(M)\n",
    "\n",
    "plaincode = _translate(plaintext, alphabet)\n",
    "ciphercode = _translate(ciphertext, alphabet)\n",
    "traincode = _translate(traintext, alphabet)\n",
    "f_true = _translate(cipher_function, alphabet)\n",
    "start_idx = np.array([0]+list(np.where(np.logical_and(traincode[:-1]==27,traincode[1:]==26))[0]+2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 100.00%\r"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "import scipy.stats as stats\n",
    "\n",
    "def _roll(x, k):\n",
    "    idx = np.random.choice(x.shape[0], k, replace=False)\n",
    "    xp = x.copy()\n",
    "    xp[idx] = xp[np.roll(idx, 1)]\n",
    "    return xp\n",
    "\n",
    "def _gen_perm(func, order, i):\n",
    "    if i % 5 == 0:\n",
    "        return np.arange(order)\n",
    "    return _roll(func, 2)\n",
    "\n",
    "def _gen_data(alphabet, traincode, start_idx, length, batch_size, num_iter):\n",
    "    order = len(alphabet)\n",
    "    pt_data, ct_data, func_data, ktau_data= [], [], [], []\n",
    "    func = None\n",
    "    for i in range(num_iter*batch_size):\n",
    "        start = np.random.choice(start_idx[:-5], 1)[0]\n",
    "        pt = traincode[start:start+length]\n",
    "        func = _gen_perm(func, order, i)\n",
    "        ct = func[pt]\n",
    "        ktau = stats.kendalltau(np.arange(order), func)[0]\n",
    "        pt_data.append(np_utils.to_categorical(pt, order))\n",
    "        ct_data.append(np_utils.to_categorical(ct, order))\n",
    "        func_data.append(np_utils.to_categorical(func, order))\n",
    "        ktau_data.append(ktau)\n",
    "        if (i+1) % batch_size == 0:\n",
    "            print('Progress: {:1.2f}%'.format((i+1)*100.0/num_iter/batch_size), end='\\r')\n",
    "    data = [pt_data, ct_data, func_data, ktau_data]\n",
    "    return tuple([np.array(d) for d in data])\n",
    "\n",
    "pt, ct, func, ktau = _gen_data(alphabet, traincode, start_idx, 64, 128, 100)\n",
    "x = ct\n",
    "y = np.exp(ktau-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/matplotlib/axes/_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f27cc82a710>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.distplot(ktau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10240 samples, validate on 2560 samples\n",
      "Epoch 1/30\n",
      "10240/10240 [==============================] - 7s 684us/step - loss: 0.0237 - mean_squared_error: 0.0237 - val_loss: 0.0142 - val_mean_squared_error: 0.0142\n",
      "Epoch 2/30\n",
      "10240/10240 [==============================] - 6s 611us/step - loss: 0.0141 - mean_squared_error: 0.0141 - val_loss: 0.0142 - val_mean_squared_error: 0.0142\n",
      "Epoch 3/30\n",
      "10240/10240 [==============================] - 7s 635us/step - loss: 0.0137 - mean_squared_error: 0.0137 - val_loss: 0.0130 - val_mean_squared_error: 0.0130\n",
      "Epoch 4/30\n",
      "10240/10240 [==============================] - 6s 619us/step - loss: 0.0135 - mean_squared_error: 0.0135 - val_loss: 0.0125 - val_mean_squared_error: 0.0125\n",
      "Epoch 5/30\n",
      "10240/10240 [==============================] - 6s 608us/step - loss: 0.0136 - mean_squared_error: 0.0136 - val_loss: 0.0128 - val_mean_squared_error: 0.0128\n",
      "Epoch 6/30\n",
      "10240/10240 [==============================] - 6s 631us/step - loss: 0.0131 - mean_squared_error: 0.0131 - val_loss: 0.0132 - val_mean_squared_error: 0.0132\n",
      "Epoch 7/30\n",
      "10240/10240 [==============================] - 6s 612us/step - loss: 0.0130 - mean_squared_error: 0.0130 - val_loss: 0.0121 - val_mean_squared_error: 0.0121\n",
      "Epoch 8/30\n",
      "10240/10240 [==============================] - 6s 609us/step - loss: 0.0129 - mean_squared_error: 0.0129 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
      "Epoch 9/30\n",
      "10240/10240 [==============================] - 6s 621us/step - loss: 0.0129 - mean_squared_error: 0.0129 - val_loss: 0.0126 - val_mean_squared_error: 0.0126\n",
      "Epoch 10/30\n",
      "10240/10240 [==============================] - 6s 615us/step - loss: 0.0127 - mean_squared_error: 0.0127 - val_loss: 0.0129 - val_mean_squared_error: 0.0129\n",
      "Epoch 11/30\n",
      "10240/10240 [==============================] - 7s 636us/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
      "Epoch 12/30\n",
      "10240/10240 [==============================] - 7s 636us/step - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.0110 - val_mean_squared_error: 0.0110\n",
      "Epoch 13/30\n",
      "10240/10240 [==============================] - 7s 635us/step - loss: 0.0119 - mean_squared_error: 0.0119 - val_loss: 0.0111 - val_mean_squared_error: 0.0111\n",
      "Epoch 14/30\n",
      "10240/10240 [==============================] - 6s 632us/step - loss: 0.0118 - mean_squared_error: 0.0118 - val_loss: 0.0121 - val_mean_squared_error: 0.0121\n",
      "Epoch 15/30\n",
      "10240/10240 [==============================] - 6s 630us/step - loss: 0.0115 - mean_squared_error: 0.0115 - val_loss: 0.0103 - val_mean_squared_error: 0.0103\n",
      "Epoch 16/30\n",
      "10240/10240 [==============================] - 7s 652us/step - loss: 0.0113 - mean_squared_error: 0.0113 - val_loss: 0.0103 - val_mean_squared_error: 0.0103\n",
      "Epoch 17/30\n",
      "10240/10240 [==============================] - 6s 604us/step - loss: 0.0111 - mean_squared_error: 0.0111 - val_loss: 0.0107 - val_mean_squared_error: 0.0107\n",
      "Epoch 18/30\n",
      "10240/10240 [==============================] - 7s 657us/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.0105 - val_mean_squared_error: 0.0105\n",
      "Epoch 19/30\n",
      "10240/10240 [==============================] - 6s 627us/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.0094 - val_mean_squared_error: 0.0094\n",
      "Epoch 20/30\n",
      "10240/10240 [==============================] - 6s 631us/step - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.0097 - val_mean_squared_error: 0.0097\n",
      "Epoch 21/30\n",
      "10240/10240 [==============================] - 7s 645us/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0093 - val_mean_squared_error: 0.0093\n",
      "Epoch 22/30\n",
      "10240/10240 [==============================] - 6s 609us/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0092 - val_mean_squared_error: 0.0092\n",
      "Epoch 23/30\n",
      "10240/10240 [==============================] - 7s 655us/step - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.0089 - val_mean_squared_error: 0.0089\n",
      "Epoch 24/30\n",
      "10240/10240 [==============================] - 6s 634us/step - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.0096 - val_mean_squared_error: 0.0096\n",
      "Epoch 25/30\n",
      "10240/10240 [==============================] - 6s 633us/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.0084 - val_mean_squared_error: 0.0084\n",
      "Epoch 26/30\n",
      "10240/10240 [==============================] - 7s 635us/step - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.0089 - val_mean_squared_error: 0.0089\n",
      "Epoch 27/30\n",
      "10240/10240 [==============================] - 6s 615us/step - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.0088 - val_mean_squared_error: 0.0088\n",
      "Epoch 28/30\n",
      "10240/10240 [==============================] - 6s 583us/step - loss: 0.0092 - mean_squared_error: 0.0092 - val_loss: 0.0088 - val_mean_squared_error: 0.0088\n",
      "Epoch 29/30\n",
      "10240/10240 [==============================] - 6s 633us/step - loss: 0.0093 - mean_squared_error: 0.0093 - val_loss: 0.0101 - val_mean_squared_error: 0.0101\n",
      "Epoch 30/30\n",
      "10240/10240 [==============================] - 6s 629us/step - loss: 0.0091 - mean_squared_error: 0.0091 - val_loss: 0.0088 - val_mean_squared_error: 0.0088\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, GRU, Reshape, Lambda\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.regularizers import l2\n",
    "from keras.metrics import mean_squared_error\n",
    "\n",
    "def _check_shape(x):\n",
    "    print(x.shape)\n",
    "    return x\n",
    "\n",
    "def _def_model(length, batch_size, order):\n",
    "    ipt = Input(batch_shape=(batch_size, length, order))\n",
    "    x = GRU(256, activation='relu', recurrent_activation='sigmoid',\n",
    "            use_bias=True, kernel_initializer='glorot_uniform', \n",
    "            recurrent_initializer='orthogonal', bias_initializer='zeros',\n",
    "            return_sequences=False, dropout=0.2, recurrent_dropout=0.2)(ipt)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    pdt = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=ipt, outputs=pdt)\n",
    "    model.compile('adam', loss=['mse'], metrics=['mse'])\n",
    "    return model\n",
    "    \n",
    "model = _def_model(64, 128, 28)\n",
    "history = model.fit(x=x, y=y, batch_size=128, epochs=30, verbose=1, validation_split=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref [1.0, 0.91005291005291, 0.8201058201058201, 0.8253968253968254, 0.8201058201058201]\n",
      "mc [-19194.68082971 -23099.67510999 -23172.68760008 -26370.6917371 ]\n",
      "nn [-16.811523 -23.578835 -23.62807  -29.830841]\n"
     ]
    }
   ],
   "source": [
    "def get_log_probs_nn(x, model, ciphercode, batch_size, length, order):\n",
    "    xinv = np.argsort(x, axis=1)\n",
    "    decodedcode = xinv[:,ciphercode[:batch_size*length].reshape(batch_size, length)].reshape((xinv.shape[0]*batch_size, length))\n",
    "    probs = model.predict(np_utils.to_categorical(decodedcode, order), batch_size=batch_size).reshape((xinv.shape[0], batch_size))\n",
    "    return np.sum(np.log(probs), axis=1)\n",
    "\n",
    "def get_log_probs_mc(x, logP, logM, ciphercode):\n",
    "    ps = np.zeros((x.shape[0], ciphercode.shape[0]))\n",
    "    xinv = np.argsort(x, axis=1)\n",
    "    ps[:,0] = logP[xinv[:,ciphercode[0]]]\n",
    "    ps[:,1:] = logM[xinv[:,ciphercode[1:]],xinv[:,ciphercode[:-1]]]\n",
    "    return np.sum(ps, axis=1)\n",
    "\n",
    "\n",
    "x = np.array([_roll(f_true, i) for i in range(1,5)])\n",
    "\n",
    "print('ref', [stats.kendalltau(f_true, func)[0] for func in funcs])\n",
    "print('mc', get_log_probs_mc(x, logP, logM, ciphercode[:64*128]))\n",
    "print('nn', get_log_probs_nn(x, model, ciphercode, 128, 64, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_log_probs() takes 5 positional arguments but 6 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-297f7533cdcf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0mlogp_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_rate_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mciphercode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplaincode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-21-297f7533cdcf>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(batch_size, order, length, model, ciphercode, plaincode, maxiter, T)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxiter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mxp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproposal_change\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mlogp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_log_probs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mciphercode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mlogp_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mlogpp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_log_probs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mciphercode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: get_log_probs() takes 5 positional arguments but 6 were given"
     ]
    }
   ],
   "source": [
    "def initialize(batch_size, order):\n",
    "    x = np.zeros((batch_size, order), dtype=np.float64)\n",
    "    for i in range(batch_size):\n",
    "        x[i,] = np.random.permutation(order)\n",
    "    return x\n",
    "\n",
    "def proposal_change(x, k):\n",
    "    def _roll(_x):\n",
    "        idx = np.random.choice(_x.shape[0], k, replace=False)\n",
    "        _x[idx] = _x[np.roll(idx, 1)]\n",
    "        return _x\n",
    "    xp = np.apply_along_axis(_roll, 1, np.copy(x))\n",
    "    return xp\n",
    "\n",
    "def get_log_probs(x, model, ciphercode, batch_size, order):\n",
    "    xinv = np.argsort(x, axis=1)\n",
    "    return np.log(model.predict(np_utils.to_categorical(xinv[:,ciphercode], order), \n",
    "                                batch_size=batch_size)).reshape(-1)\n",
    "\n",
    "def random_step(logpr):\n",
    "    pr = np.exp(np.clip(logpr, -np.inf, 0))\n",
    "    return (np.random.rand(pr.shape[0]) < pr).astype(np.int)\n",
    "\n",
    "def update(x, xp, rs):\n",
    "    rs = rs.reshape((rs.shape[0],1))\n",
    "    return (rs*xp+(1-rs)*x)\n",
    "\n",
    "def get_acc(x, ciphercode, plaincode):\n",
    "    xinv = np.argsort(x, axis=1)\n",
    "    plaincode = np.repeat(plaincode.reshape((1,-1)), x.shape[0], axis=0)\n",
    "    return np.sum((xinv[:,ciphercode] == plaincode).astype(np.int))/x.shape[0]/ciphercode.shape[0]\n",
    "\n",
    "\n",
    "def main(batch_size, order, length, model, ciphercode, plaincode, maxiter, T):\n",
    "    x = initialize(batch_size, order)\n",
    "    rs_mean = 0\n",
    "    logp_list, accept_rate_list, acc_list = [], [], []\n",
    "    for i in range(maxiter):\n",
    "        xp = proposal_change(x, 2)\n",
    "        logp = get_log_probs(x, model, ciphercode, batch_size, order, length)\n",
    "        logp_list.append(np.mean(logp))\n",
    "        logpp = get_log_probs(xp, model, ciphercode, batch_size, order, length)\n",
    "        logpr = logpp - logp\n",
    "        rs = random_step(logpr)\n",
    "        accept_rate_list.append(np.mean(rs))\n",
    "        rs_mean += np.mean(rs)/T\n",
    "        x = update(x, xp, rs)\n",
    "        acc = get_acc(x, ciphercode, plaincode)\n",
    "        acc_list.append(np.mean(acc))\n",
    "        if i % T == 0:\n",
    "            print(\"iter:{}, log_prob:{:1.4e}, accept_rate:{:1.4e}, accuracy:{:1.4e}\".format(i, np.mean(logp), rs_mean, acc))\n",
    "            rs_mean = 0\n",
    "    return logp_list, accept_rate_list, acc_list\n",
    "\n",
    "length = -1\n",
    "logp_list, accept_rate_list, acc_list = main(32, 28, 16, model, ciphercode[:length], plaincode[:length], 5000, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
